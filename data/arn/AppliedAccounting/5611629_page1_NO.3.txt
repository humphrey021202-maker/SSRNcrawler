Skip to main content
Product & Services
Research Paper Series
Site Subscriptions
Sponsored Services
Jobs & Announcements
Conference Papers
Partners in Publishing
First Look
Subscribe
Submit a paper
Browse
Rankings
Top Papers
Top Authors
Top Organizations
Blog↗
Contact
Create account
Sign in
  This is a preprint article, it offers immediate access but has not been peer reviewed.
Download This Paper
 
Open PDF in Browser
 Add Paper to My Library
Share:    
LLMs as Research Assistants: The Risk of Topic-Overclassification and Effective Mitigation Strategies in Financial Disclosure Research

64 Pages Posted: 16 Oct 2025

Anne Christine d'Arcy

Vienna University of Economics and Business

Christian Haas

Vienna University of Economics and Business

Nicolaus Wallner

WU Vienna University of Economics and Business

Abstract

Large language models (LLMs) are quickly changing how data, particularly unstructured text, is processed and analyzed. Their effectiveness compared to alternative approaches or human analysts, however, is context dependent and requires further analysis. This study investigates the potential of large language models (LLMs) as research assistants (RAs) in accounting research, particularly regarding topic modeling and information extraction from financial disclosures. By comparing OpenAI’s GPT-4o model with the traditional Latent Dirichlet Allocation (LDA) technique and human RAs, we evaluate LLMs’ current reliability in identifying the topic of mergers and acquisitions from analyst reports. Our results demonstrate that LLMs outperform LDA in generating more nuanced and interpretable topics. At the same time, they show comparable but still lower reliability than human RAs in topic classification tasks. This mainly stems from overclassification by LLMs of topic-relevant sentences compared to human RAs. Further robustness tests show that additional prompt engineering steps are effective in (partially) mitigating this risk of overclassification. Overall, our study highlights the challenge of topic-overclassification risk when using LLMs. By highlighting the need for prompt engineering, our study presents several guiding steps for better prompting in complex tasks like topic modeling and topic identification in financial disclosures.

Keywords: textual analysis, large language models, topic modeling, research assistants, financial disclosure

Suggested Citation:

d'Arcy, Anne and Haas, Christian and Wallner, Nicolaus, LLMs as Research Assistants: The Risk of Topic-Overclassification and Effective Mitigation Strategies in Financial Disclosure Research. Available at SSRN: https://ssrn.com/abstract=5611629 or http://dx.doi.org/10.2139/ssrn.5611629
Download This Paper
 
Open PDF in Browser
122 References
J C S Alvarado , K Verspoor , T Baldwin
Domain Adaption of Named Entity Recognition to Support Credit Risk Assessment
Proceedings of the Australasian Language Technology Association Workshop , p. 84 - 90 Posted: 2015
B Ampel , C.-H Yang , J Hu , H Chen
Large Language Models for Conducting Advanced Text Analytics Information Systems Research
ACM Transactions on Management Information Systems Posted: 2024
D Araci
FinBERT: Financial Sentiment Analysis with Pre-trained Language Models Posted: 2019
H Axelborn , J Berggren
Topic Modeling for Customer Insights -A Comparative Analysis of LDA and BERTopic in Categorizing Customer Calls Posted: 2023
Load more
0 Citations
Do you have a job opening that you would like to promote on SSRN?
Place Job Opening
Paper statistics
DOWNLOADS
9
ABSTRACT VIEWS
25
122 References
PlumX Metrics
Related eJournals

Research Methods & Methodology in Accounting eJournal

Follow

Applied Accounting - Practitioner eJournal

Follow
 
Feedback 
Submit a Paper 
Section 508 Text Only Pages
SSRN Quick Links
SSRN Solutions
Research Paper Series
Conference Papers
Partners in Publishing
Jobs & Announcements
Special Topic Hubs
SSRN Rankings
Top Papers
Top Authors
Top Organizations
About SSRN
Network Directors
Announcements
Contact us
FAQs
  
Copyright Terms and Conditions Privacy Policy

All content on this site: Copyright © 2024 Elsevier Inc., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.

We use cookies to help provide and enhance our service and tailor content.

To learn more, visit Cookie settings | Your Privacy Choices. 

We use cookies that are necessary to make our site work. We may also use additional cookies to analyze, improve, and personalize our content and your digital experience. For more information, see ourCookie Policy
Cookie Settings
Accept all cookies