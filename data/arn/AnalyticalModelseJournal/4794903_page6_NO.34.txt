Skip to main content
Product & Services
Research Paper Series
Site Subscriptions
Sponsored Services
Jobs & Announcements
Conference Papers
Partners in Publishing
First Look
Subscribe
Submit a paper
Browse
Rankings
Top Papers
Top Authors
Top Organizations
Blog↗
Contact
Create account
Sign in
Download This Paper
 
Open PDF in Browser
 Add Paper to My Library
Share:    
VC Theory for Inventory Policies

41 Pages Posted: 16 Apr 2024 Last revised: 10 Jun 2025

Yaqi Xie

University of Chicago - Booth School of Business

Will Ma

Columbia University - Columbia Business School, Decision Risk and Operations

Linwei Xin

Cornell University - School of Operations Research and Information Engineering

Date Written: June 09, 2025

Abstract

There has been growing interest in applying reinforcement learning to inventory management, alongside a recent stream of work advocating for supervised learning approaches that directly optimize inventory decisions using full historical demand trajectories. While empirically promising, there has been no theoretical understanding of supervised learning in inventory management problems, where inventory is dynamically replenished over time. This paper provides the first generalization guarantees for supervised learning of several well-known classes of dynamic inventory policies, including base-stock and (s, S) policies, using tools from the celebrated Vapnik-Chervonenkis (VC) theory, such as the Pseudo-dimension and Fat-shattering dimension. Our results have implications for regret against the best-in-class policies, and allow for an arbitrary distribution over demand sequences, which makes no assumptions such as independence across time.


Surprisingly, we prove that the class of policies defined by T non-stationary base-stock levels exhibits a generalization error that does not grow with T, whereas the two-parameter (s, S) policy class has a generalization error growing logarithmically with T. Overall, our analysis leverages specific inventory structures within the learning theory framework, and improves sample complexity guarantees even compared to existing results assuming independent demands.

Keywords: VC theory, Pseudo-dimension, data-driven algorithm design, generalization bound, estimation error, sample complexity, shattering, inventory, base-stock policy, (s, S) policy, less is more

Suggested Citation:

Xie, Yaqi and Ma, Will and Xin, Linwei, VC Theory for Inventory Policies (June 09, 2025). Available at SSRN: https://ssrn.com/abstract=4794903 or http://dx.doi.org/10.2139/ssrn.4794903
Download This Paper
 
Open PDF in Browser
41 References
N Alon , S Ben-David , N Cesa-Bianchi , D Haussler
Scale-sensitive dimensions, uniform convergence, and learnability
Journal of the ACM , volume 44 , issue 4 , p. 615 - 631 Posted: 1997
M Alvo , D Russo , Y Kanoria
Neural inventory control in networks via hindsight differentiable policy optimization Posted: 2023
M.-F Balcan
Data-driven algorithm design Posted: 2020
M.-F Balcan , D Deblasio , T Dick , C Kingsford , T Sandholm , E Vitercik
How much data is sufficient to learn high-performing algorithms? generalization guarantees for data-driven algorithm design
Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing , p. 919 - 932 Posted: 2021
Load more
0 Citations
Fetch Citations
Do you have a job opening that you would like to promote on SSRN?
Place Job Opening
Paper statistics
DOWNLOADS
415
ABSTRACT VIEWS
2,029
RANK
161,650
41 References
PlumX Metrics
Related eJournals

Corporate Finance: Valuation, Capital Budgeting & Investment Policy eJournal

Follow

Econometrics: Econometric & Statistical Methods - Special Topics eJournal

Follow
 
Feedback 
Submit a Paper 
Section 508 Text Only Pages
SSRN Quick Links
SSRN Solutions
Research Paper Series
Conference Papers
Partners in Publishing
Jobs & Announcements
Special Topic Hubs
SSRN Rankings
Top Papers
Top Authors
Top Organizations
About SSRN
Network Directors
Announcements
Contact us
FAQs
  
Copyright Terms and Conditions Privacy Policy

All content on this site: Copyright © 2024 Elsevier Inc., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.

We use cookies to help provide and enhance our service and tailor content.

To learn more, visit Cookie settings | Your Privacy Choices. 

We use cookies that are necessary to make our site work. We may also use additional cookies to analyze, improve, and personalize our content and your digital experience. For more information, see ourCookie Policy
Cookie Settings
Accept all cookies