Skip to main content
Product & Services
Research Paper Series
Site Subscriptions
Sponsored Services
Jobs & Announcements
Conference Papers
Partners in Publishing
First Look
Subscribe
Submit a paper
Browse
Rankings
Top Papers
Top Authors
Top Organizations
Blog↗
Contact
Create account
Sign in
Download This Paper
 
Open PDF in Browser
 Add Paper to My Library
Share:    
Entity Neutering

46 Pages Posted: 10 Apr 2025 Last revised: 12 Sep 2025

Joseph Engelberg

University of California, San Diego (UCSD) - Rady School of Management

Asaf Manela

Washington University in St. Louis - John M. Olin Business School; Reichman University

William Mullins

University of California, San Diego (UCSD)

Luka Vulicevic

University of California, San Diego (UCSD), Rady School of Management, Students

Date Written: March 17, 2025

Abstract

[Updated and improved!] Cutting-edge LLMs are trained on recent data, creating a concern about look-ahead bias. We propose a solution called entity neutering: using LLMs to find and remove all identifying information from text. Our procedure uses an LLM agent that iteratively (i) masks entity-related terms and (ii) paraphrases the text until an independent LLM fails to recognize the target company from the text. In a sample of 250,000 financial news articles we verify that, after neutering, ChatGPT and other LLMs identify the subject firm at the rate of random chance. Among the unidentified articles, the sentiment extracted from the raw text and the neutered text agree more than 95% of the time and have similar return predictability, with the difference providing an upper bound on look-ahead bias. The evidence here suggests that LLMs are able to effectively neuter text while maintaining semantic content. For look-ahead bias, LLMs can be both the problem and the solution.



Keywords: Large Language Models, Look-ahead Bias, Textual Analysis JEL Classification Numbers:, Agentic

Suggested Citation:

Engelberg, Joseph and Manela, Asaf and Mullins, William and Vulicevic, Luka, Entity Neutering (March 17, 2025). Available at SSRN: https://ssrn.com/abstract=5182756 or http://dx.doi.org/10.2139/ssrn.5182756
Download This Paper
 
Open PDF in Browser
41 References
J Bybee , Leland
The ghost in the machine: Generating beliefs with large language models Posted: 2023
Leland Bybee , Bryan Kelly , Yinan Su
Narrative asset pricing: Interpretable systematic risk factors from news text
Review of Financial Studies , volume 36 , p. 4759 - 4787 Posted: 2023
Nicholas Carlini , Daphne Ippolito , Matthew Jagielski , Katherine Lee , Florian Tramer , Chiyuan Zhang
Quantifying memorization across neural language models
The Eleventh International Conference on Learning Representations Posted: 2023
Nicholas Carlini , Florian Tramer , Eric Wallace , Matthew Jagielski , Ariel Herbert-Voss , Katherine Lee , Adam Roberts , Tom Brown , Dawn Song , Ulfar Erlingsson
Extracting training data from large language models
30th USENIX security symposium , p. 2633 - 2650 Posted: 2021
Load more
1 Citations
Alejandro Lopez-Lira , Yuehua Tang , Mingyin Zhu
The Memorization Problem: Can We Trust LLMs' Economic Forecasts?
76 Pages · Posted: 18 Apr 2025 · Last revised: 1 Oct 2025 · Downloads: 1,613
Download PDF  Add Paper to My Library
Load more
Do you have a job opening that you would like to promote on SSRN?
Place Job Opening
Paper statistics
DOWNLOADS
670
ABSTRACT VIEWS
3,457
RANK
90,016
1 Citations
41 References
PlumX Metrics
Related eJournals

Risk Management eJournal

Follow

Capital Markets: Asset Pricing & Valuation eJournal

Follow
 
Feedback 
Submit a Paper 
Section 508 Text Only Pages
SSRN Quick Links
SSRN Solutions
Research Paper Series
Conference Papers
Partners in Publishing
Jobs & Announcements
Special Topic Hubs
SSRN Rankings
Top Papers
Top Authors
Top Organizations
About SSRN
Network Directors
Announcements
Contact us
FAQs
  
Copyright Terms and Conditions Privacy Policy

All content on this site: Copyright © 2024 Elsevier Inc., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.

We use cookies to help provide and enhance our service and tailor content.

To learn more, visit Cookie settings | Your Privacy Choices. 

We use cookies that are necessary to make our site work. We may also use additional cookies to analyze, improve, and personalize our content and your digital experience. For more information, see ourCookie Policy
Cookie Settings
Accept all cookies