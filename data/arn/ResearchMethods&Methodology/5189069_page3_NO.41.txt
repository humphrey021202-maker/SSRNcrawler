Skip to main content
Product & Services
Research Paper Series
Site Subscriptions
Sponsored Services
Jobs & Announcements
Conference Papers
Partners in Publishing
First Look
Subscribe
Submit a paper
Browse
Rankings
Top Papers
Top Authors
Top Organizations
Blog↗
Contact
Create account
Sign in
Download This Paper
 
Open PDF in Browser
 Add Paper to My Library
Share:    
Assessing Consistency and Reproducibility in the Outputs of Large Language Models: Evidence Across Diverse Finance and Accounting Tasks

77 Pages Posted: 26 Mar 2025 Last revised: 13 Sep 2025

Julian Wang

University of Oxford

Victor Xiaoqi Wang

California State University, Long Beach - College of Business Administration

Date Written: March 22, 2025

Abstract

This study provides the first comprehensive assessment of consistency and reproducibility in Large Language Model (LLM) outputs in finance and accounting research. We evaluate how consistently LLMs produce outputs given identical inputs through extensive experimentation with 50 independent runs across five common tasks: classification, sentiment analysis, summarization, text generation, and prediction. Using three OpenAI models (GPT-3.5-turbo, GPT-4o-mini, and GPT-4o), we generate over 3.4 million outputs from diverse financial source texts and data, covering MD&As, FOMC statements, finance news articles, earnings call transcripts, and financial statements. Our findings reveal substantial but task-dependent consistency, with binary classification and sentiment analysis achieving near-perfect reproducibility, while complex tasks show greater variability. More advanced models do not consistently demonstrate better consistency and reproducibility, with task-specific patterns emerging. LLMs significantly outperform expert human annotators in consistency and maintain high agreement even where human experts significantly disagree. We further find that simple aggregation strategies across 3-5 runs dramatically improve consistency. We also find that aggregation may come with an additional benefit of improved accuracy for sentiment analysis when using newer models. Simulation analysis reveals that despite measurable inconsistency in LLM outputs, downstream statistical inferences remain remarkably robust. These findings address concerns about what we term "G-hacking," the selective reporting of favorable outcomes from multiple generative AI runs, by demonstrating that such risks are relatively low for finance and accounting tasks.

Keywords: Generative AI (GenAI), Large Language Models (LLMs), ChatGPT, Reproducibility, G-hacking, Classification, Sentiment analysis, Summarization, Prediction

Suggested Citation:

Wang, Julian and Wang, Victor Xiaoqi, Assessing Consistency and Reproducibility in the Outputs of Large Language Models: Evidence Across Diverse Finance and Accounting Tasks (March 22, 2025). Available at SSRN: https://ssrn.com/abstract=5189069 or http://dx.doi.org/10.2139/ssrn.5189069
Download This Paper
 
Open PDF in Browser
87 References
T Aguda , S Siddagangappa , E Kochkina , S Kaur , D Wang , C Smiley , S Shah
Large language models as financial data annotators: A study on effectiveness and efficiency Posted: 2024-03-26
H Ahmed , J Lofstead
Managing randomness to enable reproducible machine learning
Proceedings of the 5th International Workshop on Practical Reproducible Evaluation of Computer Systems P-RECS '22 , p. 15 - 20 Posted: 2022
A Alonso-Robisco , J M Carbó
Analysis of CBDC narrative by central banks using large language models
Finance Research Letters , volume 58 Posted: 2023
S Álvarez-Díez , J S Baixauli-Soler , A Kondratenko , G Lozano-Reina
Dividend announcement and the value of sentiment analysis
Journal of Management Analytics , p. 1 - 21 Posted: 2024
Load more
2 Citations
Paulina S. C. Kliem , Urs Fisch , Sira M. Baumann , Sebastian Berger , Simon A. Amacher , Sabina Hunziker , Raoul Sutter
The impact of prompting on ChatGPT’s adherence to status epilepticus treatment guidelines
Scientific Reports , volume 15 , issue 1 Posted: 2025
Crossref
Eva Blondeel , Patricia Everaert , Evelien Opdecam
A practical guide to implementing ChatGPT as a secondary coder in qualitative research
International Journal of Accounting Information Systems , volume 56 , p. 100754 Posted: 2025
Crossref
Load more
Do you have a job opening that you would like to promote on SSRN?
Place Job Opening
Paper statistics
DOWNLOADS
245
ABSTRACT VIEWS
3,910
RANK
287,519
2 Citations
87 References
PlumX Metrics
Related eJournals

Financial Accounting eJournal

Follow

Capital Markets: Asset Pricing & Valuation eJournal

Follow
 
Feedback 
Submit a Paper 
Section 508 Text Only Pages
SSRN Quick Links
SSRN Solutions
Research Paper Series
Conference Papers
Partners in Publishing
Jobs & Announcements
Special Topic Hubs
SSRN Rankings
Top Papers
Top Authors
Top Organizations
About SSRN
Network Directors
Announcements
Contact us
FAQs
  
Copyright Terms and Conditions Privacy Policy

All content on this site: Copyright © 2024 Elsevier Inc., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.

We use cookies to help provide and enhance our service and tailor content.

To learn more, visit Cookie settings | Your Privacy Choices. 

We use cookies that are necessary to make our site work. We may also use additional cookies to analyze, improve, and personalize our content and your digital experience. For more information, see ourCookie Policy
Cookie Settings
Accept all cookies